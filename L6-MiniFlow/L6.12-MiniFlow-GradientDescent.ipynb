{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We've successfully calculated a full forward pass and found the cost. Next we need to start a backwards pass, which starts with backpropagation. Backpropagation is the process by which the network runs error values backwards.\n",
    "\n",
    "During this process, the network calculates the way in which the weights need to change (also called the gradient) to reduce the overall error of the network. Changing the weights usually occurs through a technique called gradient descent.\n",
    "\n",
    "Making sense of the purpose of backpropagation comes more easily after you work through the intended outcome. I'll come back to backpropagation in a bit, but first, I want to dive deeper into gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine a point on a three dimensional surface. In real-life, a ball sitting on the slope of a valley makes a nice analogy. In this case, the height of the point represents the difference between the current output of the network and the correct output given the current parameter values (hence why you need data with known outputs). Each dimension of the plane represents another parameter to the network. A network with m parameters would be a hyperplane of m dimensions.\n",
    "\n",
    "(Imagining more than three dimensions is tricky. The good news is that the ball and valley example describes the behavior of gradient descent well, the only difference between three dimensional and n dimensional situations being the number of parameters in the calculations.)\n",
    "\n",
    "In the ideal situation, the ball rests at the bottom of the valley, indicating the minimum difference between the output of the network and the known correct output.\n",
    "\n",
    "The learning process starts with random weights and biases. In the ball analogy, the ball starts at a random point near the valley.\n",
    "\n",
    "Gradient descent works by first calculating the slope of the plane at the current point, which includes calculating the partial derivatives of the loss with respect to all of the parameters. This set of partial derivatives is called the gradient. Then it uses the gradient to modify the weights such that the next forward pass through the network moves the output lower in the hyperplane. Physically, this would be the same as measuring the slope of the valley at the location of the ball, and then moving the ball a small amount in the direction of the slope. Over time, it's possible to find the bottom of the valley with many small movements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While gradient descent works remarkably well, the technique isn't guaranteed to find the absolute minimum difference between the network's output and the known output. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Journey to the Bottom of the Valley "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know we'd like to move the ball to the bottom of the valley, but how do we accomplish this?\n",
    "\n",
    "Intuitively, we want to push the ball downhill. And that makes sense, but when we're talking about our cost function, how do we know which way is downhill?\n",
    "\n",
    "Luckily, the gradient provides this exact information.\n",
    "\n",
    "Technically, the gradient actually points uphill, in the direction of steepest ascent. But if we put a - sign at the front this value, we get the direction of steepest descent, which is what we want.\n",
    "\n",
    "You'll learn more about the gradient in a moment, but, for now, just think of it as a vector of numbers. Each number represents the amount by which we should adjust a corresponding weight or bias in the neural network. Adjusting all of the weights and biases by the gradient values reduces the cost (or error) of the network.\n",
    "\n",
    "Got all that?\n",
    "\n",
    "Great! Now we know where to push the ball. The next thing to consider is how much force should be applied to the push. This is known as the learning rate, which is an apt name since this value determines how quickly or slowly the neural network learns.\n",
    "\n",
    "You might be tempted to set a really big learning rate, so the network learns really fast, right?\n",
    "\n",
    "Be careful! If the value is too large you could overshoot the target and eventually diverge. Yikes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what is a good learning rate, then?\n",
    "\n",
    "This is more of a guessing game than anything else but empirically values in the range 0.1 to 0.0001 work well. The range 0.001 to 0.0001 is popular, as 0.1 and 0.01 are sometimes too large.\n",
    "\n",
    "Here's the formula for gradient descent (pseudocode):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x = x - learning_rate * gradient_of_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x is a parameter used by the neural network (i.e. a single weight or bias).\n",
    "\n",
    "We multiply gradient_of_x (the uphill direction) by learning_rate (the force of the push) and then subtract that from x to make the push go downhill."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this quiz you'll complete TODOs in both the f.py and gd.py files.\n",
    "\n",
    "Tasks:\n",
    "\n",
    "    Set the learning_rate in f.py.\n",
    "    Complete the gradient descent implementation in gradient_descent_update function in gd.py.\n",
    "\n",
    "Notes:\n",
    "\n",
    "    Setting the learning_rate to 0.1 should result in x -> 0 and f(x) -> 5 if you've implemented gradient descent correctly.\n",
    "    Play around with different values for the learning rate. Try very small values, values close to 1, above 1, etc. What happens?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gd.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent_update(x, gradx, learning_rate):\n",
    "    \"\"\"\n",
    "    Performs a gradient descent update.\n",
    "    \"\"\"\n",
    "    # TODO: Implement gradient descent.\n",
    "    \n",
    "    # Return the new value for x\n",
    "    x = x - learning_rate * gradx\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0: Cost = 46621589.000, x = 13656.000\n",
      "EPOCH 1: Cost = 29837818.760, x = 10924.800\n",
      "EPOCH 2: Cost = 19096205.806, x = 8739.840\n",
      "EPOCH 3: Cost = 12221573.516, x = 6991.872\n",
      "EPOCH 4: Cost = 7821808.850, x = 5593.498\n",
      "EPOCH 5: Cost = 5005959.464, x = 4474.798\n",
      "EPOCH 6: Cost = 3203815.857, x = 3579.838\n",
      "EPOCH 7: Cost = 2050443.949, x = 2863.871\n",
      "EPOCH 8: Cost = 1312285.927, x = 2291.097\n",
      "EPOCH 9: Cost = 839864.793, x = 1832.877\n",
      "EPOCH 10: Cost = 537515.268, x = 1466.302\n",
      "EPOCH 11: Cost = 344011.571, x = 1173.041\n",
      "EPOCH 12: Cost = 220169.206, x = 938.433\n",
      "EPOCH 13: Cost = 140910.092, x = 750.747\n",
      "EPOCH 14: Cost = 90184.259, x = 600.597\n",
      "EPOCH 15: Cost = 57719.726, x = 480.478\n",
      "EPOCH 16: Cost = 36942.424, x = 384.382\n",
      "EPOCH 17: Cost = 23644.952, x = 307.506\n",
      "EPOCH 18: Cost = 15134.569, x = 246.005\n",
      "EPOCH 19: Cost = 9687.924, x = 196.804\n",
      "EPOCH 20: Cost = 6202.071, x = 157.443\n",
      "EPOCH 21: Cost = 3971.126, x = 125.954\n",
      "EPOCH 22: Cost = 2543.320, x = 100.763\n",
      "EPOCH 23: Cost = 1629.525, x = 80.611\n",
      "EPOCH 24: Cost = 1044.696, x = 64.489\n",
      "EPOCH 25: Cost = 670.405, x = 51.591\n",
      "EPOCH 26: Cost = 430.860, x = 41.273\n",
      "EPOCH 27: Cost = 277.550, x = 33.018\n",
      "EPOCH 28: Cost = 179.432, x = 26.415\n",
      "EPOCH 29: Cost = 116.637, x = 21.132\n",
      "EPOCH 30: Cost = 76.447, x = 16.905\n",
      "EPOCH 31: Cost = 50.726, x = 13.524\n",
      "EPOCH 32: Cost = 34.265, x = 10.819\n",
      "EPOCH 33: Cost = 23.729, x = 8.656\n",
      "EPOCH 34: Cost = 16.987, x = 6.924\n",
      "EPOCH 35: Cost = 12.672, x = 5.540\n",
      "EPOCH 36: Cost = 9.910, x = 4.432\n",
      "EPOCH 37: Cost = 8.142, x = 3.545\n",
      "EPOCH 38: Cost = 7.011, x = 2.836\n",
      "EPOCH 39: Cost = 6.287, x = 2.269\n",
      "EPOCH 40: Cost = 5.824, x = 1.815\n",
      "EPOCH 41: Cost = 5.527, x = 1.452\n",
      "EPOCH 42: Cost = 5.337, x = 1.162\n",
      "EPOCH 43: Cost = 5.216, x = 0.929\n",
      "EPOCH 44: Cost = 5.138, x = 0.744\n",
      "EPOCH 45: Cost = 5.088, x = 0.595\n",
      "EPOCH 46: Cost = 5.057, x = 0.476\n",
      "EPOCH 47: Cost = 5.036, x = 0.381\n",
      "EPOCH 48: Cost = 5.023, x = 0.305\n",
      "EPOCH 49: Cost = 5.015, x = 0.244\n",
      "EPOCH 50: Cost = 5.009, x = 0.195\n",
      "EPOCH 51: Cost = 5.006, x = 0.156\n",
      "EPOCH 52: Cost = 5.004, x = 0.125\n",
      "EPOCH 53: Cost = 5.002, x = 0.100\n",
      "EPOCH 54: Cost = 5.002, x = 0.080\n",
      "EPOCH 55: Cost = 5.001, x = 0.064\n",
      "EPOCH 56: Cost = 5.001, x = 0.051\n",
      "EPOCH 57: Cost = 5.000, x = 0.041\n",
      "EPOCH 58: Cost = 5.000, x = 0.033\n",
      "EPOCH 59: Cost = 5.000, x = 0.026\n",
      "EPOCH 60: Cost = 5.000, x = 0.021\n",
      "EPOCH 61: Cost = 5.000, x = 0.017\n",
      "EPOCH 62: Cost = 5.000, x = 0.013\n",
      "EPOCH 63: Cost = 5.000, x = 0.011\n",
      "EPOCH 64: Cost = 5.000, x = 0.009\n",
      "EPOCH 65: Cost = 5.000, x = 0.007\n",
      "EPOCH 66: Cost = 5.000, x = 0.005\n",
      "EPOCH 67: Cost = 5.000, x = 0.004\n",
      "EPOCH 68: Cost = 5.000, x = 0.004\n",
      "EPOCH 69: Cost = 5.000, x = 0.003\n",
      "EPOCH 70: Cost = 5.000, x = 0.002\n",
      "EPOCH 71: Cost = 5.000, x = 0.002\n",
      "EPOCH 72: Cost = 5.000, x = 0.001\n",
      "EPOCH 73: Cost = 5.000, x = 0.001\n",
      "EPOCH 74: Cost = 5.000, x = 0.001\n",
      "EPOCH 75: Cost = 5.000, x = 0.001\n",
      "EPOCH 76: Cost = 5.000, x = 0.001\n",
      "EPOCH 77: Cost = 5.000, x = 0.000\n",
      "EPOCH 78: Cost = 5.000, x = 0.000\n",
      "EPOCH 79: Cost = 5.000, x = 0.000\n",
      "EPOCH 80: Cost = 5.000, x = 0.000\n",
      "EPOCH 81: Cost = 5.000, x = 0.000\n",
      "EPOCH 82: Cost = 5.000, x = 0.000\n",
      "EPOCH 83: Cost = 5.000, x = 0.000\n",
      "EPOCH 84: Cost = 5.000, x = 0.000\n",
      "EPOCH 85: Cost = 5.000, x = 0.000\n",
      "EPOCH 86: Cost = 5.000, x = 0.000\n",
      "EPOCH 87: Cost = 5.000, x = 0.000\n",
      "EPOCH 88: Cost = 5.000, x = 0.000\n",
      "EPOCH 89: Cost = 5.000, x = 0.000\n",
      "EPOCH 90: Cost = 5.000, x = 0.000\n",
      "EPOCH 91: Cost = 5.000, x = 0.000\n",
      "EPOCH 92: Cost = 5.000, x = 0.000\n",
      "EPOCH 93: Cost = 5.000, x = 0.000\n",
      "EPOCH 94: Cost = 5.000, x = 0.000\n",
      "EPOCH 95: Cost = 5.000, x = 0.000\n",
      "EPOCH 96: Cost = 5.000, x = 0.000\n",
      "EPOCH 97: Cost = 5.000, x = 0.000\n",
      "EPOCH 98: Cost = 5.000, x = 0.000\n",
      "EPOCH 99: Cost = 5.000, x = 0.000\n",
      "EPOCH 100: Cost = 5.000, x = 0.000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Given the starting point of any `x` gradient descent\n",
    "should be able to find the minimum value of x for the\n",
    "cost function `f` defined below.\n",
    "\"\"\"\n",
    "import random\n",
    "#from gd import gradient_descent_update\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    \"\"\"\n",
    "    Quadratic function.\n",
    "\n",
    "    It's easy to see the minimum value of the function\n",
    "    is 5 when is x=0.\n",
    "    \"\"\"\n",
    "    return x**2 + 5\n",
    "\n",
    "\n",
    "def df(x):\n",
    "    \"\"\"\n",
    "    Derivative of `f` with respect to `x`.\n",
    "    \"\"\"\n",
    "    return 2*x\n",
    "\n",
    "\n",
    "# Random number better 0 and 10,000. Feel free to set x whatever you like.\n",
    "x = random.randint(0, 10000)\n",
    "# TODO: Set the learning rate\n",
    "learning_rate = 0.1\n",
    "epochs = 100\n",
    "\n",
    "for i in range(epochs+1):\n",
    "    cost = f(x)\n",
    "    gradx = df(x)\n",
    "    print(\"EPOCH {}: Cost = {:.3f}, x = {:.3f}\".format(i, cost, gradx))\n",
    "    x = gradient_descent_update(x, gradx, learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pythonx]",
   "language": "python",
   "name": "conda-env-pythonx-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
