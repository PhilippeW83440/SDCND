{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L10.5-Neural Networks in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "#Create the Sequential model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keras.models.Sequential class is a wrapper for the neural network model. It provides common functions like fit(), evaluate(), and compile(). We'll cover these functions as we get to them. Let's start looking at the layers of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Layers**\n",
    "\n",
    "A Keras layer is just like a neural network layer. There are fully connected layers, max pool layers, and activation layers. You can add a layer to the model using the model's add() function. For example, a simple model would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "\n",
    "#Create the Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "#1st Layer - Add a flatten layer\n",
    "model.add(Flatten(input_shape=(32, 32, 3)))\n",
    "\n",
    "#2nd Layer - Add a fully connected layer\n",
    "model.add(Dense(100))\n",
    "\n",
    "#3rd Layer - Add a ReLU activation layer\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#4th Layer - Add a fully connected layer\n",
    "model.add(Dense(60))\n",
    "\n",
    "#5th Layer - Add a ReLU activation layer\n",
    "model.add(Activation('relu'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras will automatically infer the shape of all layers after the first layer. This means you only have to set the input dimensions for the first layer.\n",
    "\n",
    "The first layer from above, **model.add(Flatten(input_shape=(32, 32, 3)))**, sets the input dimension to (32, 32, 3) and output dimension to (3072=32 x 32 x 3). The second layer takes in the output of the first layer and sets the output dimensions to (100). This chain of passing output to the next layer continues until the last layer, which is the output of the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this quiz you will build a multi-layer feedforward neural network to classify traffic sign images using Keras.\n",
    "\n",
    "    Set the first layer to a Flatten() layer with the input_shape set to (32, 32, 3).\n",
    "    Set the second layer to a Dense() layer with an output width of 128.\n",
    "    Use a ReLU activation function after the second layer.\n",
    "    Set the output layer width to 5, because for this data set there are only 5 classes.\n",
    "    Use a softmax activation function after the output layer.\n",
    "    Train the model for 3 epochs. You should be able to get over 50% training accuracy.\n",
    "\n",
    "To get started, review the Keras documentation about models and layers. The Keras example of a Multi-Layer Perceptron network is similar to what you need to do here. Use that as a guide, but keep in mind that there are a number of differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "flatten_10 (Flatten)             (None, 3072)          0           flatten_input_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_27 (Dense)                 (None, 1024)          3146752     flatten_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, 1024)          0           dense_27[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 1024)          0           activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_28 (Dense)                 (None, 43)            44075       dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, 43)            0           dense_28[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 3190827\n",
      "____________________________________________________________________________________________________\n",
      "Train on 27839 samples, validate on 6960 samples\n",
      "Epoch 1/3\n",
      "27839/27839 [==============================] - 5s - loss: 1.7353 - acc: 0.5427 - val_loss: 12.2318 - val_acc: 0.1207\n",
      "Epoch 2/3\n",
      "27839/27839 [==============================] - 5s - loss: 0.9916 - acc: 0.7156 - val_loss: 12.4261 - val_acc: 0.1159\n",
      "Epoch 3/3\n",
      "27839/27839 [==============================] - 5s - loss: 0.7772 - acc: 0.7784 - val_loss: 12.8264 - val_acc: 0.1395\n"
     ]
    }
   ],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "with open('train.p', mode='rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_train, y_train = data['features'], data['labels']\n",
    "\n",
    "# Initial Setup for Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "\n",
    "from keras.layers import Dropout, Convolution2D, MaxPooling2D\n",
    "\n",
    "# TODO: Build the Fully Connected Neural Network in Keras Here\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(32, 32, 3)))\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(43))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# preprocess data\n",
    "X_normalized = np.array(X_train / 255.0 - 0.5 )\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "# TODO: change the number of training epochs to 3\n",
    "history = model.fit(X_normalized, y_one_hot, nb_epoch=3, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L10.6-Convolutions in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Build from the previous network.\n",
    "    Add a convolutional layer with 32 filters, a 3x3 kernel, and valid padding before the flatten layer.\n",
    "    Add a ReLU activation after the convolutional layer.\n",
    "    Train for 3 epochs again, should be able to get over 50% accuracy.\n",
    "\n",
    "Hint 1: The Keras example of a convolutional neural network for MNIST would be a good example to review.  \n",
    "https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\n",
    "\n",
    "Hint 2: You can set the padding type by passing in a border_mode= argument to the Convolution2D() layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27839 samples, validate on 6960 samples\n",
      "Epoch 1/3\n",
      "27839/27839 [==============================] - 10s - loss: 0.8180 - acc: 0.7779 - val_loss: 12.7461 - val_acc: 0.1806\n",
      "Epoch 2/3\n",
      "27839/27839 [==============================] - 10s - loss: 0.1711 - acc: 0.9568 - val_loss: 12.9292 - val_acc: 0.1911\n",
      "Epoch 3/3\n",
      "27839/27839 [==============================] - 10s - loss: 0.0949 - acc: 0.9747 - val_loss: 12.9136 - val_acc: 0.1909\n"
     ]
    }
   ],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "with open('train.p', mode='rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_train, y_train = data['features'], data['labels']\n",
    "\n",
    "# Initial Setup for Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "\n",
    "from keras.layers import Dropout, Convolution2D, MaxPooling2D\n",
    "\n",
    "# TODO: Build Convolutional Neural Network in Keras Here\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(32,32,3), border_mode='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(43))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "# preprocess data\n",
    "X_normalized = np.array(X_train / 255.0 - 0.5 )\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "# TODO: change the number of training epochs to 3\n",
    "history = model.fit(X_normalized, y_one_hot, nb_epoch=3, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L10.7-Pooling in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pooling\n",
    "\n",
    "    Build from the previous network\n",
    "    Add a 2x2 max pooling layer immediately following your convolutional layer.\n",
    "    Train for 3 epochs again. You should be able to get over 50% training accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27839 samples, validate on 6960 samples\n",
      "Epoch 1/3\n",
      "27839/27839 [==============================] - 5s - loss: 1.0025 - acc: 0.7313 - val_loss: 12.8277 - val_acc: 0.1884\n",
      "Epoch 2/3\n",
      "27839/27839 [==============================] - 5s - loss: 0.1983 - acc: 0.9510 - val_loss: 12.7695 - val_acc: 0.1931\n",
      "Epoch 3/3\n",
      "27839/27839 [==============================] - 5s - loss: 0.1105 - acc: 0.9737 - val_loss: 12.7949 - val_acc: 0.1856\n"
     ]
    }
   ],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "with open('train.p', mode='rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_train, y_train = data['features'], data['labels']\n",
    "\n",
    "# Initial Setup for Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "\n",
    "from keras.layers import Dropout, Convolution2D, MaxPooling2D\n",
    "\n",
    "# TODO: Build Convolutional Neural Network in Keras Here\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(32,32,3), border_mode='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(43))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "# preprocess data\n",
    "X_normalized = np.array(X_train / 255.0 - 0.5 )\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "# TODO: change the number of training epochs to 3\n",
    "history = model.fit(X_normalized, y_one_hot, nb_epoch=3, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L10.8-Dropout in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Build from the previous network.\n",
    "    Add a dropout layer after the pooling layer. Set the dropout rate to 50%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27839 samples, validate on 6960 samples\n",
      "Epoch 1/3\n",
      "27839/27839 [==============================] - 6s - loss: 1.0799 - acc: 0.7041 - val_loss: 12.4875 - val_acc: 0.1756\n",
      "Epoch 2/3\n",
      "27839/27839 [==============================] - 5s - loss: 0.2841 - acc: 0.9252 - val_loss: 12.7466 - val_acc: 0.1818\n",
      "Epoch 3/3\n",
      "27839/27839 [==============================] - 5s - loss: 0.1912 - acc: 0.9476 - val_loss: 12.8037 - val_acc: 0.1878\n"
     ]
    }
   ],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "with open('train.p', mode='rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_train, y_train = data['features'], data['labels']\n",
    "\n",
    "# Initial Setup for Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "\n",
    "from keras.layers import Dropout, Convolution2D, MaxPooling2D\n",
    "\n",
    "# TODO: Build Convolutional Neural Network in Keras Here\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(32,32,3), border_mode='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(43))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "# preprocess data\n",
    "X_normalized = np.array(X_train / 255.0 - 0.5 )\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "# TODO: change the number of training epochs to 3\n",
    "history = model.fit(X_normalized, y_one_hot, nb_epoch=3, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L10.8-Testing in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've picked out your best model, it's time to test it!\n",
    "\n",
    "    Try to get the highest validation accuracy possible. Feel free to use all the previous concepts and train for as many epochs as needed.\n",
    "    Select your best model and train it one more time.\n",
    "    Use the test data and the Keras evaluate() method to see how well the model does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27839 samples, validate on 6960 samples\n",
      "Epoch 1/10\n",
      "27839/27839 [==============================] - 12s - loss: 1.3618 - acc: 0.6170 - val_loss: 11.7584 - val_acc: 0.1874\n",
      "Epoch 2/10\n",
      "27839/27839 [==============================] - 11s - loss: 0.5032 - acc: 0.8475 - val_loss: 12.3631 - val_acc: 0.1907\n",
      "Epoch 3/10\n",
      "27839/27839 [==============================] - 11s - loss: 0.3709 - acc: 0.8879 - val_loss: 12.7523 - val_acc: 0.1915\n",
      "Epoch 4/10\n",
      "27839/27839 [==============================] - 12s - loss: 0.3081 - acc: 0.9065 - val_loss: 12.6736 - val_acc: 0.1912\n",
      "Epoch 5/10\n",
      "27839/27839 [==============================] - 11s - loss: 0.2660 - acc: 0.9151 - val_loss: 12.6951 - val_acc: 0.1917\n",
      "Epoch 6/10\n",
      "27839/27839 [==============================] - 11s - loss: 0.2396 - acc: 0.9257 - val_loss: 12.6956 - val_acc: 0.1912\n",
      "Epoch 7/10\n",
      "27839/27839 [==============================] - 11s - loss: 0.2257 - acc: 0.9290 - val_loss: 12.8420 - val_acc: 0.1869\n",
      "Epoch 8/10\n",
      "27839/27839 [==============================] - 11s - loss: 0.1973 - acc: 0.9383 - val_loss: 12.9179 - val_acc: 0.1911\n",
      "Epoch 9/10\n",
      "27839/27839 [==============================] - 11s - loss: 0.1910 - acc: 0.9405 - val_loss: 12.8995 - val_acc: 0.1895\n",
      "Epoch 10/10\n",
      "27839/27839 [==============================] - 11s - loss: 0.1862 - acc: 0.9415 - val_loss: 12.9223 - val_acc: 0.1908\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-d0bf042e925b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_normalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mdata_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test.p'"
     ]
    }
   ],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "with open('train.p', mode='rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_train, y_train = data['features'], data['labels']\n",
    "\n",
    "# Initial Setup for Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "# TODO: Build the Final Test Neural Network in Keras Here\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(128, 3, 3, input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(43))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# preprocess data\n",
    "X_normalized = np.array(X_train / 255.0 - 0.5 )\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "history = model.fit(X_normalized, y_one_hot, nb_epoch=10, validation_split=0.2)\n",
    "\n",
    "with open('test.p', 'rb') as f:\n",
    "    data_test = pickle.load(f)\n",
    "\n",
    "X_test = data_test['features']\n",
    "y_test = data_test['labels']\n",
    "\n",
    "# preprocess data\n",
    "X_normalized_test = np.array(X_test / 255.0 - 0.5 )\n",
    "y_one_hot_test = label_binarizer.fit_transform(y_test)\n",
    "\n",
    "print(\"Testing\")\n",
    "metrics = model.evaluate(X_normalized_test, y_one_hot_test)\n",
    "for metric_i in range(len(model.metrics_names)):\n",
    "    metric_name = model.metrics_names[metric_i]\n",
    "    metric_value = metrics[metric_i]\n",
    "    print('{}: {}'.format(metric_name, metric_value))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pythonx]",
   "language": "python",
   "name": "conda-env-pythonx-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
