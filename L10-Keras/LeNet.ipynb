{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet in Keras (tested on Traffic Sign Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 28, 28, 6)     456         convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 28, 28, 6)     0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 14, 14, 6)     0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 10, 10, 16)    2416        maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 10, 10, 16)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 5, 5, 16)      0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 400)           0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 120)           48120       flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 120)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 120)           0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 84)            10164       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 84)            0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 84)            0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 43)            3655        dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 43)            0           dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 64811\n",
      "____________________________________________________________________________________________________\n",
      "Train on 34799 samples, validate on 34799 samples\n",
      "Epoch 1/50\n",
      "34799/34799 [==============================] - 3s - loss: 2.7128 - acc: 0.2619 - val_loss: 1.3198 - val_acc: 0.6013\n",
      "Epoch 2/50\n",
      "34799/34799 [==============================] - 2s - loss: 1.3165 - acc: 0.5809 - val_loss: 0.6286 - val_acc: 0.8300\n",
      "Epoch 3/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.8728 - acc: 0.7173 - val_loss: 0.3893 - val_acc: 0.8953\n",
      "Epoch 4/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.6607 - acc: 0.7905 - val_loss: 0.2695 - val_acc: 0.9305\n",
      "Epoch 5/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.5363 - acc: 0.8286 - val_loss: 0.1874 - val_acc: 0.9478\n",
      "Epoch 6/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.4565 - acc: 0.8547 - val_loss: 0.1618 - val_acc: 0.9632\n",
      "Epoch 7/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.3931 - acc: 0.8754 - val_loss: 0.1218 - val_acc: 0.9716\n",
      "Epoch 8/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.3499 - acc: 0.8913 - val_loss: 0.1059 - val_acc: 0.9759\n",
      "Epoch 9/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.3219 - acc: 0.9011 - val_loss: 0.0939 - val_acc: 0.9805\n",
      "Epoch 10/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.3003 - acc: 0.9061 - val_loss: 0.0766 - val_acc: 0.9824\n",
      "Epoch 11/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.2659 - acc: 0.9157 - val_loss: 0.0654 - val_acc: 0.9849\n",
      "Epoch 12/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.2428 - acc: 0.9222 - val_loss: 0.0556 - val_acc: 0.9873\n",
      "Epoch 13/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.2341 - acc: 0.9275 - val_loss: 0.0518 - val_acc: 0.9882\n",
      "Epoch 14/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.2190 - acc: 0.9320 - val_loss: 0.0471 - val_acc: 0.9909\n",
      "Epoch 15/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.2055 - acc: 0.9359 - val_loss: 0.0414 - val_acc: 0.9913\n",
      "Epoch 16/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.1989 - acc: 0.9385 - val_loss: 0.0401 - val_acc: 0.9905\n",
      "Epoch 17/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.1920 - acc: 0.9410 - val_loss: 0.0438 - val_acc: 0.9925\n",
      "Epoch 18/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.1842 - acc: 0.9436 - val_loss: 0.0328 - val_acc: 0.9933\n",
      "Epoch 19/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.1738 - acc: 0.9466 - val_loss: 0.0281 - val_acc: 0.9947\n",
      "Epoch 20/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.1680 - acc: 0.9476 - val_loss: 0.0271 - val_acc: 0.9937\n",
      "Epoch 21/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.1571 - acc: 0.9519 - val_loss: 0.0244 - val_acc: 0.9951\n",
      "Epoch 22/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.1572 - acc: 0.9525 - val_loss: 0.0217 - val_acc: 0.9955\n",
      "Epoch 23/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.1562 - acc: 0.9530 - val_loss: 0.0208 - val_acc: 0.9961\n",
      "Epoch 24/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.1479 - acc: 0.9551 - val_loss: 0.0191 - val_acc: 0.9958\n",
      "Epoch 25/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.1467 - acc: 0.9560 - val_loss: 0.0194 - val_acc: 0.9955\n",
      "Epoch 26/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.1406 - acc: 0.9560 - val_loss: 0.0167 - val_acc: 0.9967\n",
      "Epoch 27/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.1310 - acc: 0.9599 - val_loss: 0.0151 - val_acc: 0.9968\n",
      "Epoch 28/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.1214 - acc: 0.9622 - val_loss: 0.0144 - val_acc: 0.9968\n",
      "Epoch 29/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.1265 - acc: 0.9609 - val_loss: 0.0150 - val_acc: 0.9972\n",
      "Epoch 30/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.1237 - acc: 0.9623 - val_loss: 0.0147 - val_acc: 0.9974\n",
      "Epoch 31/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.1246 - acc: 0.9621 - val_loss: 0.0126 - val_acc: 0.9976\n",
      "Epoch 32/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.1147 - acc: 0.9644 - val_loss: 0.0125 - val_acc: 0.9973\n",
      "Epoch 33/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.1147 - acc: 0.9656 - val_loss: 0.0121 - val_acc: 0.9978\n",
      "Epoch 34/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.1093 - acc: 0.9668 - val_loss: 0.0107 - val_acc: 0.9980\n",
      "Epoch 35/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.1062 - acc: 0.9676 - val_loss: 0.0111 - val_acc: 0.9980\n",
      "Epoch 36/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.1087 - acc: 0.9672 - val_loss: 0.0107 - val_acc: 0.9974\n",
      "Epoch 37/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.1029 - acc: 0.9678 - val_loss: 0.0099 - val_acc: 0.9981\n",
      "Epoch 38/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.1054 - acc: 0.9684 - val_loss: 0.0083 - val_acc: 0.9982\n",
      "Epoch 39/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.1041 - acc: 0.9691 - val_loss: 0.0090 - val_acc: 0.9984\n",
      "Epoch 40/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.1054 - acc: 0.9679 - val_loss: 0.0077 - val_acc: 0.9985\n",
      "Epoch 41/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.0977 - acc: 0.9717 - val_loss: 0.0180 - val_acc: 0.9954\n",
      "Epoch 42/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.1073 - acc: 0.9673 - val_loss: 0.0093 - val_acc: 0.9978\n",
      "Epoch 43/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.1000 - acc: 0.9702 - val_loss: 0.0099 - val_acc: 0.9979\n",
      "Epoch 44/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.0937 - acc: 0.9713 - val_loss: 0.0060 - val_acc: 0.9988\n",
      "Epoch 45/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.0954 - acc: 0.9715 - val_loss: 0.0103 - val_acc: 0.9978\n",
      "Epoch 46/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.0905 - acc: 0.9725 - val_loss: 0.0073 - val_acc: 0.9985\n",
      "Epoch 47/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.0900 - acc: 0.9713 - val_loss: 0.0091 - val_acc: 0.9978\n",
      "Epoch 48/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.0889 - acc: 0.9729 - val_loss: 0.0065 - val_acc: 0.9985\n",
      "Epoch 49/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.0870 - acc: 0.9726 - val_loss: 0.0054 - val_acc: 0.9991\n",
      "Epoch 50/50\n",
      "34799/34799 [==============================] - 2s - loss: 0.0872 - acc: 0.9732 - val_loss: 0.0051 - val_acc: 0.9990\n",
      "Testing\n",
      "12630/12630 [==============================] - 0s     \n",
      "loss: 0.33897991057241933\n",
      "acc: 0.9471100554424717\n"
     ]
    }
   ],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "with open('train.p', mode='rb') as f:\n",
    "    data = pickle.load(f)\n",
    "X_train, y_train = data['features'], data['labels']\n",
    "\n",
    "with open('valid.p', mode='rb') as f:\n",
    "    data_val = pickle.load(f)\n",
    "X_val, y_val = data['features'], data['labels']\n",
    "\n",
    "# Initial Setup for Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "# TODO: Build the Final Test Neural Network in Keras Here\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(6, 5, 5, input_shape=(32, 32, 3), border_mode='valid', init='glorot_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Convolution2D(16, 5, 5, border_mode='valid', init='glorot_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(120, init='glorot_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(84, init='glorot_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(43, init='glorot_normal'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# preprocess data\n",
    "X_normalized = np.array(X_train / 255.0 - 0.5 )\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "\n",
    "X_normalized_val = np.array(X_val / 255.0 - 0.5 )\n",
    "y_one_hot_val = label_binarizer.fit_transform(y_val)\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "history = model.fit(X_normalized, y_one_hot, nb_epoch=50, batch_size=128, shuffle=True, \n",
    "                    validation_data=(X_normalized_val, y_one_hot_val), verbose=1)\n",
    "\n",
    "with open('test.p', 'rb') as f:\n",
    "    data_test = pickle.load(f)\n",
    "\n",
    "X_test = data_test['features']\n",
    "y_test = data_test['labels']\n",
    "\n",
    "# preprocess data\n",
    "X_normalized_test = np.array(X_test / 255.0 - 0.5 )\n",
    "y_one_hot_test = label_binarizer.fit_transform(y_test)\n",
    "\n",
    "print(\"Testing\")\n",
    "metrics = model.evaluate(X_normalized_test, y_one_hot_test)\n",
    "for metric_i in range(len(model.metrics_names)):\n",
    "    metric_name = model.metrics_names[metric_i]\n",
    "    metric_value = metrics[metric_i]\n",
    "    print('{}: {}'.format(metric_name, metric_value))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pythonx]",
   "language": "python",
   "name": "conda-env-pythonx-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
