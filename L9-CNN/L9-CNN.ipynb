{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/convolution-schematic.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is an example of a **convolution** with a 3x3 filter and a stride of 1 being applied to data with a range of 0 to 1. The convolution for each 3x3 section is calculated against the weight, [[1, 0, 1], [0, 1, 0], [1, 0, 1]], then a bias is added to create the convolved feature on the right. In this case, the bias is zero. In TensorFlow, this is all done using **tf.nn.conv2d()** and **tf.nn.bias_add()**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Setup:**\n",
    "\n",
    "H = height, W = width, D = depth\n",
    "\n",
    "    We have an input of shape 32x32x3 (HxWxD)\n",
    "    20 filters of shape 8x8x3 (HxWxD)\n",
    "    A stride of 2 for both the height and width (S)\n",
    "    Valid padding of size 1 (P)\n",
    "\n",
    "Formula for calculating the new height or width:\n",
    "\n",
    "**new_height = (input_height - filter_height + 2 * P)/S + 1**  \n",
    "**new_width = (input_width - filter_width + 2 * P)/S + 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the shape of the output? The answer format is HxWxD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is **14x14x20**.\n",
    "\n",
    "We can get the new height and width with the formula resulting in:\n",
    "\n",
    "(32 - 8 + 2 * 1)/2 + 1 = 14\n",
    "(32 - 8 + 2 * 1)/2 + 1 = 14\n",
    "\n",
    "The new depth is equal to the number of filters, which is 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question on number of parameters without parameter sharing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without parameter sharing, each neuron in the output layer must connect to each neuron in the filter. In addition, each neuron in the output layer must also connect to a single bias neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756560\n"
     ]
    }
   ],
   "source": [
    "# 8 * 8 * 3 is the number of weights, we add 1 for the bias. \n",
    "# Each weight is assigned to every single part of the output (14 * 14 * 20). \n",
    "# So we multiply these two numbers together and we get the final answer\n",
    "print((8*8*3+1)*(14*14*20))\n",
    "# That's a HUGE amount!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question on number of parameters with parameter sharing  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With parameter sharing, each neuron in an output channel shares its weights with every other neuron in that channel. So the number of parameters is equal to the number of neurons in the filter, plus a bias neuron, all multiplied by the number of channels in the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3860\n"
     ]
    }
   ],
   "source": [
    "print((8*8*3+1)*(20))\n",
    "# That's 196 times fewer parameters!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's 3840 weights and 20 biases. This should look similar to the answer from the previous quiz. The difference being it's just 20 instead of (14 * 14 * 20). Remember, with weight sharing we use the same filter for an entire depth slice. Because of this we can get rid of 14 * 14 and be left with only 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = tf.placeholder(tf.float32, (None, 32, 32, 3)) # batch size, image H, image W, RGB\n",
    "filter_weights = tf.Variable(tf.truncated_normal((8, 8, 3, 20))) # (height, width, input_depth, output_depth)\n",
    "filter_bias = tf.Variable(tf.zeros(20))\n",
    "strides = [1, 2, 2, 1] # (batch, height, width, depth)\n",
    "padding = 'VALID'\n",
    "conv = tf.nn.conv2d(input, filter_weights, strides, padding) + filter_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the output shape of **conv** will be [1, 13, 13, 20]. It's 4D to account for batch size, but more importantly, it's not [1, 14, 14, 20].   This is because the padding algorithm TensorFlow uses is not exactly the same as the one above. An alternative algorithm is to switch **padding** from **'VALID'** to **'SAME'** which would result in an output shape of [1, 16, 16, 20]. If you're curious how padding works in TensorFlow, read this document: https://www.tensorflow.org/api_guides/python/nn#Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine how to implement a CNN in TensorFlow.\n",
    "\n",
    "TensorFlow provides the **tf.nn.conv2d()** and **tf.nn.bias_add()** functions to create your own convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output depth\n",
    "k_output = 64\n",
    "\n",
    "# Image Properties\n",
    "image_width = 10\n",
    "image_height = 10\n",
    "color_channels = 3\n",
    "\n",
    "# Convolution filter\n",
    "filter_size_width = 5\n",
    "filter_size_height = 5\n",
    "\n",
    "# Input/Image\n",
    "input = tf.placeholder(tf.float32, shape=[None, image_height, image_width, color_channels])\n",
    "\n",
    "# Weight and bias\n",
    "weight = tf.Variable(tf.truncated_normal([filter_size_height, filter_size_width, color_channels, k_output]))\n",
    "bias = tf.Variable(tf.zeros(k_output))\n",
    "\n",
    "# Apply Convolution\n",
    "# strides: (batch, height, width, depth)\n",
    "conv_layer = tf.nn.conv2d(input, weight, strides=[1, 2, 2, 1], padding='SAME')\n",
    "# Add bias\n",
    "conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "# Apply activation function\n",
    "conv_layer = tf.nn.relu(conv_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above uses the **tf.nn.conv2d()** function to compute the convolution with **weight** as the filter and **[1, 2, 2, 1]** for the strides. TensorFlow uses a stride for each **input** dimension, **[batch, input_height, input_width, input_channels]**. We are generally always going to set the stride for **batch** and **input_channels** (i.e. the first and fourth element in the **strides** array) to be **1**.\n",
    "\n",
    "You'll focus on changing **input_height** and **input_width** while setting **batch** and **input_channels** to 1. The **input_height** and **input_width** strides are for striding the filter over **input**. \n",
    "\n",
    "**This example code uses a stride of 2 with 5x5 filter over input.**\n",
    "\n",
    "The **tf.nn.bias_add()** function adds a 1-d bias to the last dimension in a matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Max Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/max-pooling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image above is an example of **max pooling with a 2x2 filter and stride of 2**. The four 2x2 colors represent each time the filter was applied to find the maximum value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conceptually, the benefit of the max pooling operation is to reduce the size of the input, and allow the neural network to focus on only the most important elements. Max pooling does this by only retaining the maximum value for each filtered area, and removing the remaining values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow provides the **tf.nn.max_pool()** function to apply max pooling to your convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply Max Pooling\n",
    "conv_layer = tf.nn.max_pool(\n",
    "    conv_layer,\n",
    "    ksize=[1, 2, 2, 1],\n",
    "    strides=[1, 2, 2, 1],\n",
    "    padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **tf.nn.max_pool()** function performs max pooling with the **ksize** parameter as the size of the filter and the **strides** parameter as the length of the stride. **2x2 filters with a stride of 2x2 are common in practice**.\n",
    "\n",
    "The **ksize** and **strides** parameters are structured as 4-element lists, with each element corresponding to a dimension of the input tensor (**[batch, height, width, channels]**). For both **ksize** and **strides**, the batch and channel dimensions are typically set to **1**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max pooling is generally used to:\n",
    "    * decrease the size of the output\n",
    "    * prevent overfitting\n",
    "Preventing overfitting is a consequence of reducing the output size, which in turn, reduces the number of parameters in future layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recently, pooling layers have fallen out of favor. Some reasons are:\n",
    "\n",
    "    * Recent datasets are so big and complex we're more concerned about underfitting.\n",
    "    * Dropout is a much better regularizer.\n",
    "    * Pooling results in a loss of information. Think about the max pooling operation as an example. We only keep the largest of n numbers, thereby disregarding n-1 numbers completely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz Max Pooling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H = height, W = width, D = depth\n",
    "\n",
    "    We have an input of shape 4x4x5 (HxWxD)\n",
    "    Filter of shape 2x2 (HxW)\n",
    "    A stride of 2 for both the height and width (S)\n",
    "\n",
    "Recall the formula for calculating the new height or width:\n",
    "\n",
    "**new_height = (input_height - filter_height)/S + 1  \n",
    "new_width = (input_width - filter_width)/S + 1**\n",
    "\n",
    "NOTE: For a pooling layer the output depth is the same as the input depth. Additionally, the pooling operation is applied individually for each depth slice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the shape of the output? Format is HxWxD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0 2.0\n"
     ]
    }
   ],
   "source": [
    "H1=(4-2)/2+1\n",
    "W1=(4-2)/2+1\n",
    "print(H1,W1)\n",
    "D=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2x2x5\n"
     ]
    }
   ],
   "source": [
    "print('%dx%dx%d'%(H1,W1,D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the corresponding code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = tf.placeholder(tf.float32, (None, 4, 4, 5))\n",
    "filter_shape = [1, 2, 2, 1]\n",
    "strides = [1, 2, 2, 1]\n",
    "padding = 'VALID'\n",
    "pool = tf.nn.max_pool(input, filter_shape, strides, padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shape of **pool** will be [1, 2, 2, 5], even if **padding** is changed to **'SAME'**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the result of a max pooling operation on the input:\n",
    "\n",
    "[[[0, 1, 0.5, 10],\n",
    "   [2, 2.5, 1, -8],\n",
    "   [4, 0, 5, 6],\n",
    "   [15, 1, 2, 3]]]\n",
    "\n",
    "Assume the filter is 2x2 and the stride is 2 for both height and width. The output shape is 2x2x1.\n",
    "\n",
    "The answering format will be 4 numbers, each separated by a comma, such as: 1,2,3,4.\n",
    "\n",
    "Work from the top left to the bottom right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5 10 15 6\n"
     ]
    }
   ],
   "source": [
    "print(2.5,10,15,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the result of a average (or mean) pooling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.375 0.875 5.0 4.0\n"
     ]
    }
   ],
   "source": [
    "print((0+1+2+2.5)/4,(.5+10+1-8)/4,(4+0+15+1)/4,(5+6+2+3)/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Full convolutional network in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../datasets/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ../datasets/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ../datasets/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../datasets/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('../datasets/mnist', one_hot=True, reshape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.00001\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Number of samples to calculate validation and accuracy\n",
    "# Decrease this if you're running out of memory to calculate accuracy\n",
    "test_valid_size = 256\n",
    "\n",
    "# Network Parameters\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75  # Dropout, probability to keep units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),     # 32 filters 5x5, in:1 out:32\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),    # 64 filters 5x5, in:32 out:64\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),    # FC: flatten 7x7x64 --> 1024 units\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))} # FC: 1024 --> 10\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convolution\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **tf.nn.conv2d()** function computes the convolution against weight **W** as shown above.\n",
    "\n",
    "In TensorFlow, **strides** is an array of 4 elements; the first element in this array indicates the stride for batch and last element indicates stride for features. It's good practice to remove the batches or features you want to skip from the data set rather than use a stride to skip them. You can always set the first and last element to 1 in **strides** in order to use all batches and features.\n",
    "\n",
    "The middle two elements are the strides for height and width respectively. I've mentioned stride as one number because you usually have a square stride where **height = width**. When someone says they are using a stride of 3, they usually mean **tf.nn.conv2d(x, W, strides=[1, 3, 3, 1])**.\n",
    "\n",
    "To make life easier, the code is using **tf.nn.bias_add()** to add the bias. Using **tf.add()** doesn't work when the tensors aren't the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# max pooling\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(\n",
    "        x,\n",
    "        ksize=[1, k, k, 1],\n",
    "        strides=[1, k, k, 1],\n",
    "        padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **tf.nn.max_pool()** function does exactly what you would expect, it performs max pooling with the **ksize** parameter as the size of the filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Layer 1 - 28*28*1 to 14*14*32\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Layer 2 - 14*14*32 to 7*7*64\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer - 7*7*64 to 1024\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output Layer - class prediction - 1024 to 10\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, we're creating 3 layers alternating between convolutions and max pooling followed by a fully connected and output layer. The transformation of each layer to new dimensions are shown in the comments. For example, the first layer shapes the images from 28x28x1 to 28x28x32 in the convolution step. Then next step applies max pooling, turning each sample into 14x14x32. All the layers are applied from **conv1** to **output**, producing 10 class predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 429 -Loss:  1238.9299 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 429 -Loss:   933.5107 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 429 -Loss:   529.3239 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 429 -Loss:   277.0436 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 429 -Loss:   353.6198 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch 429 -Loss:   211.7828 Validation Accuracy: 0.828125\n",
      "Epoch  7, Batch 429 -Loss:   205.2637 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 429 -Loss:   233.9811 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 429 -Loss:   245.9134 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 429 -Loss:   162.3698 Validation Accuracy: 0.832031\n",
      "Testing Accuracy: 0.828125\n"
     ]
    }
   ],
   "source": [
    "# Session: now let's run it\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(mnist.train.num_examples//batch_size):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "\n",
    "        # Calculate batch loss and accuracy\n",
    "        loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.})\n",
    "        valid_acc = sess.run(accuracy, feed_dict={\n",
    "                x: mnist.validation.images[:test_valid_size],\n",
    "                y: mnist.validation.labels[:test_valid_size],\n",
    "                keep_prob: 1.})\n",
    "\n",
    "        print('Epoch {:>2}, Batch {:>3} -'\n",
    "              'Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(epoch + 1, batch + 1, loss, valid_acc))\n",
    "\n",
    "    # Calculate Test Accuracy\n",
    "    test_acc = sess.run(accuracy, feed_dict={\n",
    "        x: mnist.test.images[:test_valid_size],\n",
    "        y: mnist.test.labels[:test_valid_size],\n",
    "        keep_prob: 1.})\n",
    "    print('Testing Accuracy: {}'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quizz: Using Convolution Layers in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now apply what we've learned to build real CNNs in TensorFlow. In the below exercise, you'll be asked to set up the dimensions of the Convolution filters, the weights, the biases. This is in many ways the trickiest part to using CNNs in TensorFlow. Once you have a sense of how to set up the dimensions of these attributes, applying CNNs will be far more straight forward.\n",
    "Review\n",
    "\n",
    "You should go over the TensorFlow documentation for 2D convolutions: https://www.tensorflow.org/api_guides/python/nn#Convolution. Most of the documentation is straightforward, except perhaps the padding argument. The padding might differ depending on whether you pass 'VALID' or 'SAME'.\n",
    "\n",
    "Here are a few more things worth reviewing:\n",
    "\n",
    "    TensorFlow Variables.\n",
    "    Truncated Normal Distributions in TensorFlow (you'll want to initialize your weights with a truncated normal distribution).\n",
    "    How to determine the dimensions of the output based on the input size and the filter size (shown below). You'll use this to determine what the size of your filter should be.\n",
    "\n",
    "**new_height = (input_height - filter_height + 2 * P)/S + 1  \n",
    "new_width = (input_width - filter_width + 2 * P)/S + 1**\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "    Finish off each TODO in the conv2d function.  \n",
    "    Setup the strides, padding and filter weight/bias (F_w and F_b) such that the output shape is (1, 2, 2, 3).   \n",
    "    Note that all of these except strides should be TensorFlow variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setup the strides, padding and filter weight/bias such that\n",
    "the output shape is (1, 2, 2, 3).\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# `tf.nn.conv2d` requires the input be 4D (batch_size, height, width, depth)\n",
    "# (1, 4, 4, 1)\n",
    "x = np.array([\n",
    "    [0, 1, 0.5, 10],\n",
    "    [2, 2.5, 1, -8],\n",
    "    [4, 0, 5, 6],\n",
    "    [15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))\n",
    "X = tf.constant(x)\n",
    "\n",
    "\n",
    "def conv2d(input):\n",
    "    # Filter (weights and bias)\n",
    "    # The shape of the filter weight is (height, width, input_depth, output_depth)\n",
    "    # The shape of the filter bias is (output_depth,)\n",
    "    # TODO: Define the filter weights `F_W` and filter bias `F_b`.\n",
    "    # NOTE: Remember to wrap them in `tf.Variable`, they are trainable parameters after all.\n",
    "    F_W = tf.Variable(tf.truncated_normal([3, 3, 1, 3])) # 3 filters 3x3, in:1 out:3\n",
    "    F_b = tf.Variable(tf.zeros([3]))\n",
    "    # TODO: Set the stride for each dimension (batch_size, height, width, depth)\n",
    "    strides = [1, 2, 2, 1]\n",
    "    # TODO: set the padding, either 'VALID' or 'SAME'.\n",
    "    padding = 'SAME'\n",
    "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#conv2d\n",
    "    # `tf.nn.conv2d` does not include the bias computation so we have to add it ourselves after.\n",
    "    return tf.nn.conv2d(input, F_W, strides, padding) + F_b\n",
    "\n",
    "out = conv2d(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### proposed solution\n",
    "NOTE: there's more than 1 way to get the correct output shape. Your answer might differ from mine.\n",
    "def conv2d(input):\n",
    "    # Filter (weights and bias)\n",
    "    F_W = tf.Variable(tf.truncated_normal((2, 2, 1, 3)))\n",
    "    F_b = tf.Variable(tf.zeros(3))\n",
    "    strides = [1, 2, 2, 1]\n",
    "    padding = 'VALID'\n",
    "    return tf.nn.conv2d(input, F_W, strides, padding) + F_b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quizz: Using Pooling Layers in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below exercise, you'll be asked to set up the dimensions of the pooling filters, strides, as well as the appropriate padding. You should go over the TensorFlow documentation for **tf.nn.max_pool()**: https://www.tensorflow.org/api_docs/python/tf/nn/max_pool. Padding works the same as it does for a convolution.\n",
    "Instructions\n",
    "\n",
    "   Finish off each TODO in the maxpool function.\n",
    "\n",
    "   Setup the **strides, padding and ksize** such that the output shape after pooling is **(1, 2, 2, 1)**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Set the values to `strides` and `ksize` such that\n",
    "the output shape after pooling is (1, 2, 2, 1).\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# `tf.nn.max_pool` requires the input be 4D (batch_size, height, width, depth)\n",
    "# (1, 4, 4, 1)\n",
    "x = np.array([\n",
    "    [0, 1, 0.5, 10],\n",
    "    [2, 2.5, 1, -8],\n",
    "    [4, 0, 5, 6],\n",
    "    [15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))\n",
    "X = tf.constant(x)\n",
    "\n",
    "def maxpool(input):\n",
    "    # TODO: Set the ksize (filter size) for each dimension (batch_size, height, width, depth)\n",
    "    ksize = [1, 2, 2, 1]\n",
    "    # TODO: Set the stride for each dimension (batch_size, height, width, depth)\n",
    "    strides = [1, 2, 2, 1]\n",
    "    # TODO: set the padding, either 'VALID' or 'SAME'.\n",
    "    padding = 'SAME'\n",
    "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#max_pool\n",
    "    return tf.nn.max_pool(input, ksize, strides, padding)\n",
    "    \n",
    "out = maxpool(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### proposed solution\n",
    "NOTE: there's more than 1 way to get the correct output shape. Your answer might differ from mine.  \n",
    "def maxpool(input):\n",
    "    ksize = [1, 2, 2, 1]  \n",
    "    strides = [1, 2, 2, 1]  \n",
    "    padding = 'VALID'  \n",
    "    return tf.nn.max_pool(input, ksize, strides, padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pythonx]",
   "language": "python",
   "name": "conda-env-pythonx-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
