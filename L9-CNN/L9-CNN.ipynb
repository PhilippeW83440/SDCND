{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup\n",
    "\n",
    "H = height, W = width, D = depth\n",
    "\n",
    "    We have an input of shape 32x32x3 (HxWxD)\n",
    "    20 filters of shape 8x8x3 (HxWxD)\n",
    "    A stride of 2 for both the height and width (S)\n",
    "    Valid padding of size 1 (P)\n",
    "\n",
    "Formula for calculating the new height or width:\n",
    "\n",
    "**new_height = (input_height - filter_height + 2 * P)/S + 1**  \n",
    "**new_width = (input_width - filter_width + 2 * P)/S + 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the shape of the output? The answer format is HxWxD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is **14x14x20**.\n",
    "\n",
    "We can get the new height and width with the formula resulting in:\n",
    "\n",
    "(32 - 8 + 2 * 1)/2 + 1 = 14\n",
    "(32 - 8 + 2 * 1)/2 + 1 = 14\n",
    "\n",
    "The new depth is equal to the number of filters, which is 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question on number of parameters without parameter sharing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without parameter sharing, each neuron in the output layer must connect to each neuron in the filter. In addition, each neuron in the output layer must also connect to a single bias neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756560\n"
     ]
    }
   ],
   "source": [
    "# 8 * 8 * 3 is the number of weights, we add 1 for the bias. \n",
    "# Each weight is assigned to every single part of the output (14 * 14 * 20). \n",
    "# So we multiply these two numbers together and we get the final answer\n",
    "print((8*8*3+1)*(14*14*20))\n",
    "# That's a HUGE amount!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question on number of parameters with parameter sharing  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With parameter sharing, each neuron in an output channel shares its weights with every other neuron in that channel. So the number of parameters is equal to the number of neurons in the filter, plus a bias neuron, all multiplied by the number of channels in the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3860\n"
     ]
    }
   ],
   "source": [
    "print((8*8*3+1)*(20))\n",
    "# That's 196 times fewer parameters!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's 3840 weights and 20 biases. This should look similar to the answer from the previous quiz. The difference being it's just 20 instead of (14 * 14 * 20). Remember, with weight sharing we use the same filter for an entire depth slice. Because of this we can get rid of 14 * 14 and be left with only 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = tf.placeholder(tf.float32, (None, 32, 32, 3)) # batch size, image H, image W, RGB\n",
    "filter_weights = tf.Variable(tf.truncated_normal((8, 8, 3, 20))) # (height, width, input_depth, output_depth)\n",
    "filter_bias = tf.Variable(tf.zeros(20))\n",
    "strides = [1, 2, 2, 1] # (batch, height, width, depth)\n",
    "padding = 'VALID'\n",
    "conv = tf.nn.conv2d(input, filter_weights, strides, padding) + filter_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the output shape of **conv** will be [1, 13, 13, 20]. It's 4D to account for batch size, but more importantly, it's not [1, 14, 14, 20].   This is because the padding algorithm TensorFlow uses is not exactly the same as the one above. An alternative algorithm is to switch **padding** from **'VALID'** to **'SAME'** which would result in an output shape of [1, 16, 16, 20]. If you're curious how padding works in TensorFlow, read this document: https://www.tensorflow.org/api_guides/python/nn#Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine how to implement a CNN in TensorFlow.\n",
    "\n",
    "TensorFlow provides the **tf.nn.conv2d()** and **tf.nn.bias_add()** functions to create your own convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output depth\n",
    "k_output = 64\n",
    "\n",
    "# Image Properties\n",
    "image_width = 10\n",
    "image_height = 10\n",
    "color_channels = 3\n",
    "\n",
    "# Convolution filter\n",
    "filter_size_width = 5\n",
    "filter_size_height = 5\n",
    "\n",
    "# Input/Image\n",
    "input = tf.placeholder(tf.float32, shape=[None, image_height, image_width, color_channels])\n",
    "\n",
    "# Weight and bias\n",
    "weight = tf.Variable(tf.truncated_normal([filter_size_height, filter_size_width, color_channels, k_output]))\n",
    "bias = tf.Variable(tf.zeros(k_output))\n",
    "\n",
    "# Apply Convolution\n",
    "# strides: (batch, height, width, depth)\n",
    "conv_layer = tf.nn.conv2d(input, weight, strides=[1, 2, 2, 1], padding='SAME')\n",
    "# Add bias\n",
    "conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "# Apply activation function\n",
    "conv_layer = tf.nn.relu(conv_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above uses the **tf.nn.conv2d()** function to compute the convolution with **weight** as the filter and **[1, 2, 2, 1]** for the strides. TensorFlow uses a stride for each **input** dimension, **[batch, input_height, input_width, input_channels]**. We are generally always going to set the stride for **batch** and **input_channels** (i.e. the first and fourth element in the **strides** array) to be **1**.\n",
    "\n",
    "You'll focus on changing **input_height** and **input_width** while setting **batch** and **input_channels** to 1. The **input_height** and **input_width** strides are for striding the filter over **input**. \n",
    "\n",
    "**This example code uses a stride of 2 with 5x5 filter over input.**\n",
    "\n",
    "The **tf.nn.bias_add()** function adds a 1-d bias to the last dimension in a matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Max Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/max-pooling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image above is an example of **max pooling with a 2x2 filter and stride of 2**. The four 2x2 colors represent each time the filter was applied to find the maximum value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conceptually, the benefit of the max pooling operation is to reduce the size of the input, and allow the neural network to focus on only the most important elements. Max pooling does this by only retaining the maximum value for each filtered area, and removing the remaining values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow provides the **tf.nn.max_pool()** function to apply max pooling to your convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply Max Pooling\n",
    "conv_layer = tf.nn.max_pool(\n",
    "    conv_layer,\n",
    "    ksize=[1, 2, 2, 1],\n",
    "    strides=[1, 2, 2, 1],\n",
    "    padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **tf.nn.max_pool()** function performs max pooling with the **ksize** parameter as the size of the filter and the **strides** parameter as the length of the stride. **2x2 filters with a stride of 2x2 are common in practice**.\n",
    "\n",
    "The **ksize** and **strides** parameters are structured as 4-element lists, with each element corresponding to a dimension of the input tensor (**[batch, height, width, channels]**). For both **ksize** and **strides**, the batch and channel dimensions are typically set to **1**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max pooling is generally used to:\n",
    "    * decrease the size of the output\n",
    "    * prevent overfitting\n",
    "Preventing overfitting is a consequence of reducing the output size, which in turn, reduces the number of parameters in future layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recently, pooling layers have fallen out of favor. Some reasons are:\n",
    "\n",
    "    * Recent datasets are so big and complex we're more concerned about underfitting.\n",
    "    * Dropout is a much better regularizer.\n",
    "    * Pooling results in a loss of information. Think about the max pooling operation as an example. We only keep the largest of n numbers, thereby disregarding n-1 numbers completely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz Max Pooling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H = height, W = width, D = depth\n",
    "\n",
    "    We have an input of shape 4x4x5 (HxWxD)\n",
    "    Filter of shape 2x2 (HxW)\n",
    "    A stride of 2 for both the height and width (S)\n",
    "\n",
    "Recall the formula for calculating the new height or width:\n",
    "\n",
    "**new_height = (input_height - filter_height)/S + 1  \n",
    "new_width = (input_width - filter_width)/S + 1**\n",
    "\n",
    "NOTE: For a pooling layer the output depth is the same as the input depth. Additionally, the pooling operation is applied individually for each depth slice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the shape of the output? Format is HxWxD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0 2.0\n"
     ]
    }
   ],
   "source": [
    "H1=(4-2)/2+1\n",
    "W1=(4-2)/2+1\n",
    "print(H1,W1)\n",
    "D=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2x2x5\n"
     ]
    }
   ],
   "source": [
    "print('%dx%dx%d'%(H1,W1,D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the corresponding code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = tf.placeholder(tf.float32, (None, 4, 4, 5))\n",
    "filter_shape = [1, 2, 2, 1]\n",
    "strides = [1, 2, 2, 1]\n",
    "padding = 'VALID'\n",
    "pool = tf.nn.max_pool(input, filter_shape, strides, padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shape of **pool** will be [1, 2, 2, 5], even if **padding** is changed to **'SAME'**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the result of a max pooling operation on the input:\n",
    "\n",
    "[[[0, 1, 0.5, 10],\n",
    "   [2, 2.5, 1, -8],\n",
    "   [4, 0, 5, 6],\n",
    "   [15, 1, 2, 3]]]\n",
    "\n",
    "Assume the filter is 2x2 and the stride is 2 for both height and width. The output shape is 2x2x1.\n",
    "\n",
    "The answering format will be 4 numbers, each separated by a comma, such as: 1,2,3,4.\n",
    "\n",
    "Work from the top left to the bottom right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5 10 15 6\n"
     ]
    }
   ],
   "source": [
    "print(2.5,10,15,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the result of a average (or mean) pooling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.375 0.875 5.0 4.0\n"
     ]
    }
   ],
   "source": [
    "print((0+1+2+2.5)/4,(.5+10+1-8)/4,(4+0+15+1)/4,(5+6+2+3)/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pythonx]",
   "language": "python",
   "name": "conda-env-pythonx-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
